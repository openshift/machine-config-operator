apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: machine-config-daemon
  namespace: {{.TargetNamespace}}
spec:
  selector:
    matchLabels:
      k8s-app: machine-config-daemon
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 10%
  template:
    metadata:
      name: machine-config-daemon
      labels:
        k8s-app: machine-config-daemon
      annotations:
        target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
        openshift.io/required-scc: privileged
    spec:
      containers:
      - name: machine-config-daemon
        image: {{.Images.MachineConfigOperator}}
        ports:
        - containerPort: 8798
          hostIP: 127.0.0.1
          name: health
          protocol: TCP
        command: ["/usr/bin/machine-config-daemon"]
        args:
          - "start"
          - "--payload-version={{.ReleaseVersion}}"
          - "--v={{.LogLevel}}"
          - "--tls-cipher-suites={{join .TLSCipherSuites ","}}"
          - "--tls-min-version={{.TLSMinVersion}}"
        resources:
          requests:
            cpu: 20m
            memory: 50Mi
        securityContext:
          privileged: true
          readOnlyRootFilesystem: false
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
          - mountPath: /rootfs
            name: rootfs
            mountPropagation: HostToContainer
        livenessProbe:
          initialDelaySeconds: 120
          periodSeconds: 30
          failureThreshold: 3
          httpGet:
            host: 127.0.0.1
            scheme: HTTP
            port: 8798
            path: /health
        env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          {{if .ControllerConfig.Proxy}}
          {{if .ControllerConfig.Proxy.HTTPProxy}}
          - name: HTTP_PROXY
            value: {{.ControllerConfig.Proxy.HTTPProxy}}
          {{end}}
          {{if .ControllerConfig.Proxy.HTTPSProxy}}
          - name: HTTPS_PROXY
            value: {{.ControllerConfig.Proxy.HTTPSProxy}}
          {{end}}
          {{if .ControllerConfig.Proxy.NoProxy}}
          - name: NO_PROXY
            value: "{{.ControllerConfig.Proxy.NoProxy}}"
          {{end}}
          {{end}}
      - name: kube-rbac-proxy
        image: {{.Images.KubeRbacProxy}}
        ports:
        - containerPort: 9001
          name: metrics
          protocol: TCP
        args:
        - --secure-listen-address=0.0.0.0:9001
        - --config-file=/etc/kube-rbac-proxy/config-file.yaml
        - --tls-cipher-suites={{join .TLSCipherSuites ","}} 
        - --tls-min-version={{.TLSMinVersion}}
        - --upstream=http://127.0.0.1:8797
        - --logtostderr=true
        - --tls-cert-file=/etc/tls/private/tls.crt
        - --tls-private-key-file=/etc/tls/private/tls.key
        resources:
          requests:
            cpu: 20m
            memory: 50Mi
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/tls/private
          name: proxy-tls
        - mountPath: /etc/kube-rbac-proxy
          name: mcd-auth-proxy-config
      hostNetwork: true
      hostPID: true
      serviceAccountName: machine-config-daemon
      terminationGracePeriodSeconds: 600
      nodeSelector:
        kubernetes.io/os: linux
      priorityClassName: "system-node-critical"
      volumes:
        - name: rootfs
          hostPath:
            path: /
        - name: proxy-tls
          secret:
            secretName: proxy-tls
        - configMap:
            name: kube-rbac-proxy
          name: mcd-auth-proxy-config
      tolerations:
      # MCD needs to run everywhere. Tolerate all taints.
      - operator: Exists
