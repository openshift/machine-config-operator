apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: machine-config-controller
  namespace: openshift-machine-config-operator
  labels:
    k8s-app: machine-config-controller
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
spec:
  groups:
    - name: mcc-paused-pool-kubelet-ca
      rules:
        - alert: MachineConfigControllerPausedPoolKubeletCA
          expr: |
             max by (namespace,pool) (last_over_time(machine_config_controller_paused_pool_kubelet_ca[5m])) > 0
          for: 60m
          labels:
            severity: warning
          annotations:
            summary: "Paused machine configuration pool '{{$labels.pool}}' is blocking a necessary certificate rotation and must be unpaused before the current kube-apiserver-to-kubelet-signer certificate expires on {{ $value | humanizeTimestamp }}."
            description: "Machine config pools have a 'pause' feature, which allows config to be rendered, but prevents it from being rolled out to the nodes. This alert indicates that a certificate rotation has taken place, and the new kubelet-ca certificate bundle has been rendered into a machine config, but because the pool '{{$labels.pool}}' is paused, the config cannot be rolled out to the nodes in that pool. You will notice almost immediately that for nodes in pool '{{$labels.pool}}', pod logs will not be visible in the console and interactive commands (oc log, oc exec, oc debug, oc attach) will not work. You must unpause machine config pool '{{$labels.pool}}' to let the certificates through before the kube-apiserver-to-kubelet-signer certificate expires on {{ $value | humanizeTimestamp }} or this pool's nodes will cease to function properly."
            runbook_url: https://github.com/openshift/blob/master/alerts/machine-config-operator/MachineConfigControllerPausedPoolKubeletCA.md
        - alert: MachineConfigControllerPausedPoolKubeletCA
          expr: |
             max by (namespace,pool) (last_over_time(machine_config_controller_paused_pool_kubelet_ca[5m]) - time()) < (86400 * 14) AND max by (namespace,pool) (last_over_time(machine_config_controller_paused_pool_kubelet_ca[5m])) > 0
          for: 60m
          labels:
            severity: critical
          annotations:
            summary: "Paused machine configuration pool '{{$labels.pool}}' is blocking a necessary certificate rotation and must be unpaused before the current kube-apiserver-to-kubelet-signer certificate expires in {{ $value | humanizeDuration }}."
            description: "Machine config pools have a 'pause' feature, which allows config to be rendered, but prevents it from being rolled out to the nodes. This alert indicates that a certificate rotation has taken place, and the new kubelet-ca certificate bundle has been rendered into a machine config, but because the pool '{{$labels.pool}}' is paused, the config cannot be rolled out to the nodes in that pool. You will notice almost immediately that for nodes in pool '{{$labels.pool}}', pod logs will not be visible in the console and interactive commands (oc log, oc exec, oc debug, oc attach) will not work. You must unpause machine config pool '{{$labels.pool}}' to let the certificates through before the kube-apiserver-to-kubelet-signer certificate expires. You have approximately {{ $value | humanizeDuration }} remaining before this happens and nodes in '{{$labels.pool}}' cease to function properly." 
            runbook_url: https://github.com/openshift/blob/master/alerts/machine-config-operator/MachineConfigControllerPausedPoolKubeletCA.md
    - name: os-image-override.rules
      rules:
        - expr: sum(os_image_url_override)
          record: os_image_url_override:sum
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: machine-config-daemon
  namespace: openshift-machine-config-operator
  labels:
    k8s-app: machine-config-daemon
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
spec:
  groups:
    - name: mcd-reboot-error
      rules:
        - alert: MCDRebootError
          expr: |
             mcd_reboot_err > 0
          labels:
            severity: critical
          annotations:
            message: "Reboot failed on {{ $labels.node }} , update may be blocked"
    - name: mcd-drain-error
      rules:
        - alert: MCDDrainError
          expr: |
            mcd_drain_err > 0
          labels:
            severity: warning
          annotations:
            message: "Drain failed on {{ $labels.node }} , updates may be blocked. For more details check MachineConfigController pod logs: oc logs -f -n {{ $labels.namespace }} machine-config-controller-xxxxx -c machine-config-controller"
    - name: mcd-pivot-error
      rules:
        - alert: MCDPivotError
          expr: |
            mcd_pivot_err > 0
          labels:
            severity: warning
          annotations:
            message: "Error detected in pivot logs on {{ $labels.node }} "
    - name: mcd-kubelet-health-state-error
      rules:
        - alert: KubeletHealthState
          expr: |
            mcd_kubelet_state > 2
          labels:
            severity: warning
          annotations:
            message: "Kubelet health failure threshold reached"
    - name: system-memory-exceeds-reservation
      rules:
        - alert: SystemMemoryExceedsReservation
          expr: |
            sum by (node) (container_memory_rss{id="/system.slice"}) > ((sum by (node) (kube_node_status_capacity{resource="memory"} - kube_node_status_allocatable{resource="memory"})) * 0.95)
          for: 15m
          labels:
            severity: warning
          annotations:
            message: "System memory usage of {{ $value | humanize }} on {{ $labels.node }} exceeds 95% of the reservation. Reserved memory ensures system processes can function even when the node is fully allocated and protects against workload out of memory events impacting the proper functioning of the node. The default reservation is expected to be sufficient for most configurations and should be increased (https://docs.openshift.com/container-platform/latest/nodes/nodes/nodes-nodes-managing.html) when running nodes with high numbers of pods (either due to rate of change or at steady state)."
    - name: high-overall-control-plane-memory
      rules:
        - alert: HighOverallControlPlaneMemory
          expr: |
            (
              1
              -
              sum (
                node_memory_MemFree_bytes
                + node_memory_Buffers_bytes
                + node_memory_Cached_bytes
                AND on (instance)
                label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
              ) / sum (
                node_memory_MemTotal_bytes
                AND on (instance)
                label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
              )
            ) * 100 > 60
          for: 1h
          labels:
            severity: warning
          annotations:
            summary: >-
              Memory utilization across all control plane nodes is high, and could impact responsiveness and stability.
            description: >-
              Given three control plane nodes, the overall memory utilization may only be about 2/3 of all available capacity.
              This is because if a single control plane node fails, the kube-apiserver and etcd my be slow to respond.
              To fix this, increase memory of the control plane nodes.
    - name: extremely-high-individual-control-plane-memory
      rules:
        - alert: ExtremelyHighIndividualControlPlaneMemory
          expr: |
            (
              1
              -
              sum by (instance) (
                node_memory_MemFree_bytes
                + node_memory_Buffers_bytes
                + node_memory_Cached_bytes
                AND on (instance)
                label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
              ) / sum by (instance) (
                node_memory_MemTotal_bytes
                AND on (instance)
                label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
              )
            ) * 100 > 90
          for: 45m
          labels:
            severity: critical
          annotations:
            summary: >-
              Extreme memory utilization per node within control plane nodes is extremely high, and could impact responsiveness and stability.
            description: >-
              The memory utilization per instance within control plane nodes influence the stability, and responsiveness of the cluster.
              This can lead to cluster instability and slow responses from kube-apiserver or failing requests specially on etcd.
              Moreover, OOM kill is expected which negatively influences the pod scheduling.
              If this happens on container level, the descheduler will not be able to detect it, as it works on the pod level.
              To fix this, increase memory of the affected node of control plane nodes.